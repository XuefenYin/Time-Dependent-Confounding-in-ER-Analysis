---
title: "ER1_DH2(Dynamic dosing)_ORR_TTE"
author: "Xuefen Yin"
date: "2024-12-2"
output: html_document
---
#1 R setup
```{r setup, echo = F}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

rm(list=ls(all=TRUE))

library(tidyverse)
library(mrgsolve)
library(ggplot2)
library(gridExtra)
library(survival)
library(survminer)
library(ggExtra)
# library(patchwork)
# library(ggridges)
library(purrr)
library(grid)
# library(cowplot)
library(openxlsx)
# library(brms) ## Emax
library(broom)
library(readxl)
library(zoo)

new_path <- paste("C:/rtools44/usr/bin", "C:/rtools44/mingw64/bin", Sys.getenv("PATH"), sep=";")
Sys.setenv(PATH = new_path)

theme_set(theme_bw())

custom_theme <- theme_classic() +
  theme(
    panel.grid.major = element_line(color = "gray70", linewidth = 0.5),  # Major grid lines
    panel.grid.minor = element_line(color = "gray90", linewidth = 0.25)  # Minor grid lines
  )

custom_log_labels <- function(x) {
  ifelse(x < 10, 
         sprintf("%.1f", x),  # One decimal place for numbers < 10
         sprintf("%.0f", x))  # No decimal places for numbers >= 10
}

my.theme = theme_bw() +
  theme(plot.background  = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.text      = element_text(size = 7),
        legend.title     = element_text(size = 7),
        axis.title       = element_text(size = 18),
        axis.text        = element_text(size = 12),
        legend.key.width = unit(.5,"cm"))

quantiles_Five <- function(data, column_name, labels = c("1", "2", "3", "4", "5")) {
  quantiles <- quantile(data[[column_name]], probs = seq(0.2, 0.8, by = 0.2))
  categorized_column <- cut(data[[column_name]],
                            breaks = c(-Inf, quantiles, Inf),
                            labels = labels,
                            include.lowest = TRUE)
  return(categorized_column)
}

# used for loop function
logistic_analysis <- function(logistic_Results, covariates) {
  logistic_summaries <- lapply(logistic_Results, summary)
  
  logistic.results <- lapply(seq_along(logistic_summaries), function(i) {
    x <- logistic_summaries[[i]]
    P.value <- signif(x$coefficients[2, 4], digits=3)
    Slope <- signif(x$coefficients[2, 1], digits=3)
    AIC <- round(AIC(logistic_Results[[i]]), 1)   
    res <- c(Slope, AIC, P.value)
    names(res) <- c("Slope","AIC", "P.Value")
    return(res)
  })
  
  result_df <- as.data.frame(do.call(rbind, logistic.results))
  row.names(result_df) <- covariates  
  
  return(result_df)
}

univ_con <- function(univ_models) {
    univ_results <- lapply(univ_models, function(x) {
    x <- summary(x)  # Summarize the model
    # Extract and format the results
    P.value <- signif(x$wald["pvalue"], digits=3)
    wald.test <- signif(x$wald["test"], digits=3)
    beta <- signif(x$coef[1], digits=3)  # Coefficient beta
    HR <- signif(exp(x$coef[1]), digits=3)  # Hazard Ratio (HR)
    HR.confint.lower <- signif(x$conf.int[,"lower .95"], 3)
    HR.confint.upper <- signif(x$conf.int[,"upper .95"], 3)
    HR <- paste0(HR, " (",
                 HR.confint.lower, "-", HR.confint.upper, ")")
    res <- c(beta, HR, wald.test, P.value)
    names(res) <- c("beta", "HR (95% CI for HR)", "wald.test", "P.Value")
    return(res)
  })
  # Convert the list of results to a dataframe
  result_df <- t(as.data.frame(univ_results))
  return(result_df)
}

```
#2_1 Generate the df.exp 
- Can used the results generateed by "ER1_DH2_1Dose_BOR.Rmd", saved in "ER2_DH2_AE_HL24_ii24"
```{r echo=FALSE}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis")
##input the PKPD individual parameters
parameter <- read.csv("estimated individual PK parameters.csv")
# mrgsolve model
PKPD_model<- mread_cache("PKPD_tumor_DH2_AE.mod") 

## Dose level for the 1 to 500 ID 
FHDOSE <- 100
FMDOSE <- 60
FLDOSE <- 40

## Dose level for the 501 to 1000 ID 
HDOSE <- 500
MDOSE <- 200
LDOSE <- 100

# Generate dose_label
high_sdose_label <- c("0mg", paste0(c(LDOSE, MDOSE, HDOSE), "mg"))
low_sdose_label <- c("0mg", paste0(c(FLDOSE, FMDOSE, FHDOSE), "mg"))
# Generate legend.labels_dose
legend.labels_high_sdose <- paste0("Q", 1:4, ": ", hight_sdose_label)
legend.labels_low_sdose <- paste0("Q", 1:4, ": ", low_sdose_label)
#bootstrap the PK parameters

id.seed = 20817
set.seed(id.seed)
ID.unique <- unique(parameter$SUBJID) 
ID.bootstrap <- sample(ID.unique, 1000, replace = TRUE)


iparameter <- data.frame()
       
       for (i in 1:length(ID.bootstrap)) {
                id <- ID.bootstrap[i]
                rows_for_id <- parameter[parameter$SUBJID == id, ]
                rows_for_id$NEWID <- i
                iparameter<- bind_rows(iparameter, rows_for_id)
         }
        
iparameter <- iparameter %>% rename(ID=NEWID)

iparameter.allID <- iparameter %>%
                    mutate(
                          DOSEI = ifelse(ID < 501, FHDOSE, HDOSE),
                          DOSEII = ifelse(ID < 501, FMDOSE, MDOSE),
                          DOSEIII = ifelse(ID < 501, FLDOSE, LDOSE),
                          KA = KA * 20,
                          CL = CL * 5
                        ) %>%
                    select(-SUBJID, -D2, -ALAG1)
       

ID.MAX <-max(iparameter.allID$ID)
evnt <- ev(amt=0, ii=24, ID=1:ID.MAX)

set.seed(id.seed)
out.pkpd <- PKPD_model%>%
            idata_set( iparameter.allID)%>%
            ev(evnt)%>%
            mrgsim(
               tgrid = c(seq(0, 24*600, by = 1)),
               carry.out = "EVID", 
               recsort = 3,
               atol = 1e-12,
               rtol = 1e-10 )

out_df <- as.data.frame(out.pkpd)

# calculate the exposure metrics
exp <- out_df %>% 
  filter(EVID == 0) %>%
  select(-EVID,-GUT,-CENT,-PERIPH,-KA, -V2, -Q, -V3, -TR, -LPBase, -LPSlope)%>%
  mutate(DAY = ceiling(time/24),
         CP = if_else(CP < 0, 0, CP), # replace the really small CP to 0
         AUC = if_else(AUC < 0, 0,AUC))%>%  # replace the negative AUC to 0
  filter(time > 0)%>%
  mutate(CavgTE = AUC/time)%>%  # average concentration time to event
  group_by(ID, DAY) %>%
  mutate(Cmax = max(CP),
         Ctrough = tail(CP,1)) %>%
  rename(DOSE=Dose) %>%
  ungroup() 
  
 #used to plot the first dosing interval profile
exp.1.hour<- exp %>%
          rename(TumorB= Tumor_0,
                 AUCTE=AUC,
                 Kgrow=KG,
                 kdecay=KD)%>%
          select(ID,DAY,DOSE, AE,time,CL,TumorB, Kgrow, kdecay, EMAX, EC50, Ktol, Tumor, CP,Cmax,Ctrough,AUCTE,CavgTE)

# used to conduct ER analysis 
exp.1<- exp.1.hour%>% filter(time %% 24 == 0)

AUC1D <- exp.1 %>%
  group_by(ID) %>%
  # Calculate the last AUCTE for each day for each ID
  group_by(DAY, .add = TRUE) %>%
  summarize(LastAUCTE = last(AUCTE), .groups = 'drop_last') %>%
  # Calculate daily AUC for each ID
  group_by(ID) %>%
  mutate(AUC1D = LastAUCTE - lag(LastAUCTE, default=0)) %>%
  ungroup()%>%
  select(-LastAUCTE)%>%
  mutate(AUC1D = if_else(AUC1D < 0, 0,AUC1D))

Combined.data <- left_join(exp.1, AUC1D, by = c("ID", "DAY"))

# calculate all possible necessary exposure matrix
exp.2 <- Combined.data%>%
  group_by(ID) %>%
  mutate(AUC1W = rollsum(AUC1D, 7, fill = NA, align = "right"),
         AUC2W = rollsum(AUC1D, 14, fill = NA, align = "right"),
         AUC3W = rollsum(AUC1D, 21, fill = NA, align = "right"),
         AUC4W = rollsum(AUC1D, 28, fill = NA, align = "right"),
         Cavg = AUC1D / 24,
         Cavg1W = AUC1W / (24*7),
         Cavg2W = AUC2W / (24*14),
         Cavg3W = AUC3W / (24*21),
         Cavg4W = AUC4W / (24*28)) %>%
  ungroup()%>%
  select(-time, -AUCTE,-AUC1D,-AUC1W,-AUC2W,-AUC3W,-AUC4W)%>%
  mutate(Cavg1W = ifelse(is.na(Cavg1W), CavgTE, Cavg1W),
         Cavg2W = ifelse(is.na(Cavg2W), CavgTE, Cavg2W),
         Cavg3W = ifelse(is.na(Cavg3W), CavgTE, Cavg3W),
         Cavg4W = ifelse(is.na(Cavg4W), CavgTE, Cavg4W))

exp.3 <- exp.2 %>%
          group_by(ID) %>%
          mutate(
                Cavg1WC1 = if_else(DAY > 7, Cavg1W, Cavg1W[DAY == 7]),
                Cavg2WC1 = if_else(DAY > 14, Cavg2W, Cavg2W[DAY == 14]),
                Cavg4WC1 = if_else(DAY > 28, Cavg4W, Cavg4W[DAY == 28]),
                CavgTE2WC1 = if_else(DAY > 14, CavgTE, Cavg2W[DAY == 14]),
                CavgTE4WC1 = if_else(DAY > 28, CavgTE, Cavg4W[DAY == 28])
                ) %>%
          ungroup()

## Calculate the accumulative average dose
df.exp <- exp.3 %>%
  group_by(ID) %>%
  arrange(ID, DAY) %>%
  mutate(CMDOSE = cumsum(DOSE)) %>%
  ungroup() %>%
  mutate(avgDOSE = CMDOSE/DAY) %>%
  select(ID, DAY, DOSE,AE, CMDOSE, avgDOSE,  everything())

setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
saveRDS(df.exp, file = "df_exp.rds")
```
#2_2 Directly input df.exp (run2_1 or 2_2)
```{r}
# setwd(C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
# 
# seed <- 20871
# 
# ## Dose level for the 1 to 500 ID 
# FHDOSE <- 100
# FMDOSE <- 60
# FLDOSE <- 40
# 
# ## Dose level for the 501 to 1000 ID 
# HDOSE <- 500
# MDOSE <- 200
# LDOSE <- 100
# 
# # Generate dose_label
# hight_sdose_label <- c("0mg", paste0(c(LDOSE, MDOSE, HDOSE), "mg"))
# low_sdose_label <- c("0mg", paste0(c(FLDOSE, FMDOSE, FHDOSE), "mg"))
# # Generate legend.labels_dose
# legend.labels_high_sdose <- paste0("Q", 1:4, ": ", hight_sdose_label)
# legend.labels_low_sdose <- paste0("Q", 1:4, ": ", low_sdose_label)
```

#3 Simulate time to event dataset(TTE)

There scenarios will be explored:
- EO1: shape = 0.65, scale = 100;
- EO2: shape = 2, scale = 240;

75% of records are event times, which has a weibull distribution
- the hazard rate could be changed by using weibull distribution, 
- when shape < 1; the hazard rate will decrease with the time
- when shape = 1; it will reduce to exponential distribution, and has a constant hazard rate
- when shape > 1; hazard rate will increase with the time
- scale = 1/rate; used to adjust the hazard rate

25% of records are censor times, which are randomly selected with replacement from the follow-up period

Note: the maximum follow-up time is 600 days; the percentage of censor data is less than 10% before the median survival time.
```{r}
n.event = 750
n.censor= 250
plot_x_scale <- 600

seed <- 123
event.shape <- 0.65
event.scale <- 100
set.seed(seed)
Sample.event <- tibble(ID = 1:n.event) %>% 
                mutate(time = 1 + ceiling(rweibull(n.event, shape = event.shape, scale = event.scale )),
                       event=1) 

set.seed(seed+6)
censor.time <- sample(1:600, n.censor, replace = TRUE)

Sample.censor <- tibble(ID = 1:n.censor) %>% 
                mutate(time = censor.time, event=1) 

Sample.censor <- Sample.censor %>% mutate(event=0)

merge.data <- rbind(Sample.event, Sample.censor)

TTE <- merge.data %>%
       mutate(event = if_else(time > 600, 0, event),
       ID = sample(1:1000, n(), replace = FALSE))%>% 
       arrange(ID)
```

#4 Create the df_ER_IDQ dataset for biased ER analysis
##4.1 Creat df.ER.IDQ dataset

-Merge the two dataset by ID
```{r}
df.ER <- data.frame()

for (i in 1:1000) {
  single <- TTE$time[i]
  rows_for_id <- df.exp[df.exp$ID == i, ]
  max_day <- max(rows_for_id$DAY, na.rm = TRUE)
  
  if (max_day < single) {
    rows_for_id$EVENT <- 0
    max_row <- which.max(rows_for_id$DAY)
    rows_for_id$LAST <- ifelse(1:nrow(rows_for_id) == max_row, 1, 0)
  } else {
    #Cut off the extra data that Day > single
    rows_for_id <- rows_for_id[rows_for_id$DAY <= single, ]
    max_row <- which.max(rows_for_id$DAY)
    #match the Event when TTE has censored values
    rows_for_id$EVENT <- ifelse(1:nrow(rows_for_id) == max_row, TTE$event[TTE$ID == i], 0)
    rows_for_id$LAST <- ifelse(1:nrow(rows_for_id) == max_row, 1, 0)
  }
   df.ER <- bind_rows(df.ER, rows_for_id)
}


analysis <- df.ER %>% filter(LAST == 1)

First_day_conc <- df.exp %>% filter(DAY==1)%>% select(ID, Ctrough, Cavg)%>% rename(Ctrough1D=Ctrough, Cavg1D=Cavg)
df.ER_correct <-  left_join(analysis, First_day_conc, by = c("ID"))

df.ER.IDQ <-df.ER_correct %>%
  rename(CmaxOED=Cmax,
         CtroughOED=Ctrough,
         CavgOED=Cavg,
         Cavg1WOED=Cavg1W,
         Cavg2WOED=Cavg2W,
         Cavg4WOED=Cavg4W)

setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
write.csv(df.ER.IDQ, "df_ER_IDQ.csv", row.names = FALSE)

```
##4.2  event% vs % of each dose level_ORR
Note: the dosing history plot for ORR and PFS are different due to the dataset df.ER is cut off at different day for each ID.
The better dishistory plot should used the one generated from PFS
```{r}
# setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
# df.ER.IDQ <- read.csv("df_ER_IDQ.csv")
# df.exp <- readRDS("df_exp.rds")

# for the Higher starting dose
 # Count and prepare totals
 EventDATA <- df.ER.IDQ %>% filter(ID<501) %>% select(DAY, EVENT)%>% arrange(DAY)
 Utime <- unique(EventDATA$DAY)
  
# Number at risk and number of events at each time
 ni <- sapply(Utime, function(t) sum(EventDATA$DAY >= t))
 di <- sapply(Utime, function(t) sum(EventDATA$DAY == t & EventDATA$EVENT == 1))
 Event_probs <- 1-cumprod(1-di/ni)

CumEvent <- data.frame(DAY = Utime, PEvent = Event_probs* 100)
     
# Count and prepare totals
DosehistG <- df.exp %>%
  filter(ID<501) %>%
  select(ID, DOSE,DAY) %>%
  count(DAY, DOSE, name = "freq") %>%
  group_by(DAY) %>%
  mutate(TOTAL = sum(freq)) %>%
  ungroup()%>%
  mutate(percentage = (freq / TOTAL) * 100)%>%
  mutate(DOSE = as.factor(DOSE))


DE.plot <- ggplot() +
   geom_col(data = CumEvent, aes(x = DAY, y = PEvent), color = "grey40", fill = "grey40", alpha = 0.01) + 
   geom_line(data = DosehistG, aes(x = DAY, y = percentage, group = DOSE, color = DOSE), size = 1) +
   scale_x_continuous(name = "Days since first dose") +
   scale_y_continuous(name = "Failure probability", sec.axis = sec_axis(~ . * 1, name = "% of dose level")) +
   ggtitle("Dose vs event summary plot") +
   scale_color_discrete(name = "Dose", labels = low_sdose_label) +
   custom_theme +
   theme(legend.title = element_blank(),
         legend.text = element_text(size = 12),
         plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
         axis.text.x = element_text(size = 10),
         axis.text.y = element_text(size = 10),
         axis.title.x = element_text(hjust = 0.5, size = 12),
         axis.title.y = element_text(hjust = 0.5, size = 12))

DE.plot

DE.PLOT2<- DE.plot + xlim(0, 150)

ggsave("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100/Dose vs event summary plot_low.tiff",
             plot = DE.plot, 
             width = 5, height = 3, dpi = 400, units = "in")

# for low starting dose
 # Count and prepare totals
 EventDATA <- df.ER.IDQ %>% filter(ID>500)%>% select(DAY, EVENT) %>% arrange(DAY)
 Utime <- unique(EventDATA$DAY)
  
# Number at risk and number of events at each time
 ni <- sapply(Utime, function(t) sum(EventDATA$DAY >= t))
 di <- sapply(Utime, function(t) sum(EventDATA$DAY == t & EventDATA$EVENT == 1))
 Event_probs <- 1-cumprod(1-di/ni)

CumEvent <- data.frame(DAY = Utime, PEvent = Event_probs* 100)
     
# Count and prepare totals
DosehistG <- df.exp %>%
  filter(ID>500) %>%
  select(ID, DOSE,DAY) %>%
  count(DAY, DOSE, name = "freq") %>%
  group_by(DAY) %>%
  mutate(TOTAL = sum(freq)) %>%
  ungroup()%>%
  mutate(percentage = (freq / TOTAL) * 100)%>%
  mutate(DOSE = as.factor(DOSE))


DE.plot <- ggplot() +
   geom_col(data = CumEvent, aes(x = DAY, y = PEvent), color = "grey40", fill = "grey40", alpha = 0.01) + 
   geom_line(data = DosehistG, aes(x = DAY, y = percentage, group = DOSE, color = DOSE), size = 1) +
   scale_x_continuous(name = "Days since first dose") +
   scale_y_continuous(name = "Failure probability", sec.axis = sec_axis(~ . * 1, name = "% of dose level")) +
   ggtitle("Dose vs event summary plot") +
   scale_color_discrete(name = "Dose", labels = high_sdose_label) +
   custom_theme +
   theme(legend.title = element_blank(),
         legend.text = element_text(size = 12),
         plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
         axis.text.x = element_text(size = 10),
         axis.text.y = element_text(size = 10),
         axis.title.x = element_text(hjust = 0.5, size = 12),
         axis.title.y = element_text(hjust = 0.5, size = 12))

DE.plot

DE.PLOT2<- DE.plot + xlim(0, 150)

ggsave("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100/Dose vs event summary plot_high.tiff",
             plot = DE.plot, 
             width = 5, height = 3, dpi = 400, units = "in")
```


#5 Model performance comparison

###5.1 generate plots_did not consider log transformation
```{r}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
df.ER.IDQ <- read.csv("df_ER_IDQ.csv")

## get the prediction results
covariates <- c( "Ctrough1D", "Cavg1D","CtroughOED", "CavgOED", "Cavg1WOED","CavgTE")
logistic_formulas <- sapply(covariates, function(x) as.formula(paste('EVENT ~', x)))
logistic_Results_plot <- lapply(logistic_formulas, function(formula) {
  # Fit the logistic regression model
  model <- glm(formula, family = binomial(), data = df.ER.IDQ)
  
  # Extract the current covariate name
  covariate <- all.vars(formula)[2]
  
  # Generate a sequence of x-values for the covariate
  # Ensure that x-values are positive since log(x) is undefined for x <= 0
  x_min <- max(0.1, min(df.ER.IDQ[[covariate]], na.rm = TRUE))  # Start from 0.1 to avoid log(0)
  x_max <- max(df.ER.IDQ[[covariate]], na.rm = TRUE)
  x_values <- seq(x_min, x_max, length.out = 500)  # 100 points for smooth curves
  
  # Create a new data frame for predictions
  new_data <- data.frame(x_values)
  names(new_data) <- covariate
  
  # Generate predictions on the logit (link) scale with standard errors
  predictions <- predict(model, newdata = new_data, type = "link", se.fit = TRUE)
  
  # Calculate the lower and upper bounds on the logit scale
  link_lower <- predictions$fit - 1.96 * predictions$se.fit
  link_upper <- predictions$fit + 1.96 * predictions$se.fit
  
  # Transform the predictions and confidence intervals back to the probability scale
  predicted_prob <- plogis(predictions$fit)
  lower_prob <- plogis(link_lower)
  upper_prob <- plogis(link_upper)
  
  # Return a data frame with the results
  data.frame(
    Covariate = x_values,
    Predicted_Prob = predicted_prob,
    Lower_Bound = lower_prob,
    Upper_Bound = upper_prob
  )
})

wb <- createWorkbook()
for (i in seq_along(covariates)) {
  addWorksheet(wb, covariates[i])  # Create a sheet named after the covariate
  writeData(wb, sheet = covariates[i], logistic_Results_plot [[i]])  # Write the data frame to the sheet
}

# Save the workbook to a file
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
saveWorkbook(wb, "logistic_regression_results_nolog.xlsx", overwrite = TRUE)
```
###5.2 generate plots_consider log transformation

```{r}
## get the prediction results
covariates <- c( "Ctrough1D", "Cavg1D","CtroughOED", "CavgOED", "Cavg1WOED", "CavgTE")
logistic_formulas <- sapply(covariates, function(x) as.formula(paste('EVENT ~ log(', x, ')')))

logistic_Results_plot <- lapply(logistic_formulas, function(formula) {
  # Fit the logistic regression model
  model <- glm(formula, family = binomial(), data = df.ER.IDQ)
  
  # Extract the current covariate name
  covariate <- all.vars(formula)[2]
  
  # Generate a sequence of x-values for the covariate
  # Ensure that x-values are positive since log(x) is undefined for x <= 0
  x_min <- max(0.1, min(df.ER.IDQ[[covariate]], na.rm = TRUE))  # Start from 0.1 to avoid log(0)
  x_max <- max(df.ER.IDQ[[covariate]], na.rm = TRUE)
  x_values <- seq(x_min, x_max, length.out = 500)  # 100 points for smooth curves
  
  # Create a new data frame for predictions
  new_data <- data.frame(x_values)
  names(new_data) <- covariate
  
  # Generate predictions on the logit (link) scale with standard errors
  predictions <- predict(model, newdata = new_data, type = "link", se.fit = TRUE)
  
  # Calculate the lower and upper bounds on the logit scale
  link_lower <- predictions$fit - 1.96 * predictions$se.fit
  link_upper <- predictions$fit + 1.96 * predictions$se.fit
  
  # Transform the predictions and confidence intervals back to the probability scale
  predicted_prob <- plogis(predictions$fit)
  lower_prob <- plogis(link_lower)
  upper_prob <- plogis(link_upper)
  
  # Return a data frame with the results
  data.frame(
    Covariate = x_values,
    Predicted_Prob = predicted_prob,
    Lower_Bound = lower_prob,
    Upper_Bound = upper_prob
  )
})

wb <- createWorkbook()
for (i in seq_along(covariates)) {
  addWorksheet(wb, covariates[i])  # Create a sheet named after the covariate
  writeData(wb, sheet = covariates[i], logistic_Results_plot [[i]])  # Write the data frame to the sheet
}

summary(logistic_Results_plot)
# Save the workbook to a file
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
saveWorkbook(wb, "logistic_regression_results_log.xlsx", overwrite = TRUE)
```

##5.3 VPC_using 5 quantiles
```{r}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
df.ER.IDQ <- read.csv("df_ER_IDQ.csv")


create_covariate_plot <- function(covariate_name) {
  # Read data
  setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
  file_path <- "logistic_regression_results_nolog.xlsx"
  Prediction <- read_excel(file_path, sheet = covariate_name)
  
   setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
  file_path <- "logistic_regression_results_log.xlsx"
  Prediction_log <- read_excel(file_path, sheet = covariate_name)
  
  # Calculate statistics
  covariate_stats <- quantile(df.ER.IDQ[[covariate_name]], probs = c(0.05, 0.5, 0.95), na.rm = TRUE)
  names(covariate_stats) <- c("p05", "med", "p95")
  
  # Prepare plot data
  eff.stats <- df.ER.IDQ %>%
    group_by(!!sym(paste0(covariate_name, "_IDQ"))) %>%
    summarise(N = n(),
              NResp = sum(EVENT == 1),
              Minimum = min(!!sym(covariate_name)),
              Median = median(!!sym(covariate_name)),
              Maximum = max(!!sym(covariate_name)),
              ObsProb = round(NResp / N, 4)) %>%
    mutate(bins = paste0(row_number(), "^", c("st", "nd", "rd", rep("th", n() - 3)), "^ quartile")) %>%
    select(bins, N, Minimum, Median, Maximum, NResp, ObsProb) %>%
    group_by(bins) %>%
    mutate(exact.lower = binom.test(NResp, N)$conf.int[1],
           exact.upper = binom.test(NResp, N)$conf.int[2]) %>%
    as.data.frame()
  
  # Create plot
  p <- ggplot() +
    geom_jitter(data = df.ER.IDQ, aes(x = !!sym(covariate_name), y = EVENT, color = "Observation"), alpha = 0.2, size = 1, height = 0.03) +
    
    geom_line(data = Prediction, aes(x = Covariate, y = Predicted_Prob, color = "No log transformation"), size = 1.5) +
    geom_ribbon(data = Prediction, aes(x = Covariate, ymin = Lower_Bound, ymax = Upper_Bound), alpha = 0.2, fill = "blue") +
    
    
    geom_line(data = Prediction_log, aes(x = Covariate, y = Predicted_Prob, color = "Log transformation"), size = 1.5) +
    geom_ribbon(data = Prediction_log, aes(x = Covariate, ymin = Lower_Bound, ymax = Upper_Bound), alpha = 0.2, fill = "red") +
    
    geom_errorbar(data = eff.stats, aes(x = Median, ymin = exact.lower, ymax = exact.upper), size = 1.1, width = 0.1) +
    geom_point(data = eff.stats, aes(x = Median, y = ObsProb), size = 2) +
    geom_segment(aes(x = min(eff.stats$Minimum), xend = max(eff.stats$Maximum), y = -0.05, yend = -0.05), size = 1.1) +
    geom_segment(data = eff.stats, aes(x = Minimum, xend = Minimum, y = -0.07, yend = -0.03), size = 1.1) +
    geom_segment(data = eff.stats[nrow(eff.stats), ], aes(x = Maximum, xend = Maximum, y = -0.07, yend = -0.03), size = 1.1) +
    geom_vline(xintercept = covariate_stats["med"], linetype = 'solid') +
    geom_vline(xintercept = covariate_stats["p05"], linetype = 'dashed') +
    geom_vline(xintercept = covariate_stats["p95"], linetype = 'dashed') +
    scale_color_manual(values = c("Observation" = "black", "No log transformation" = "blue", "Log transformation" = "red")) +
    my.theme +
    xlab(covariate_name) + 
    ylab("Probability of Responder") +
    ggtitle(paste("Model comparison: log vs no log -", covariate_name)) +
    theme(
      legend.position = c(0.3, 0.3),
      legend.background = element_rect(fill = "transparent"),
      legend.title = element_blank(),
      legend.text = element_text(size = 12),
      legend.key.size = unit(0.5, "cm"),
      axis.text.x = element_text(size = 12, angle = 0, hjust = 1),
      axis.text.y = element_text(size = 12),
      axis.title = element_text(size = 12),
      plot.title = element_text(size = 14, hjust = 0.5),
      plot.margin = unit(c(0.2, 0.2, 0.2, 0.2), "cm")
    )
  
  return(p)
}

# split dataset into 5 quantiles

df.ER.IDQ$Ctrough1D_IDQ  <- quantiles_Five(df.ER.IDQ, "Ctrough1D")
df.ER.IDQ$CtroughOED_IDQ  <- quantiles_Five(df.ER.IDQ, "CtroughOED")
df.ER.IDQ$Cavg1D_IDQ  <- quantiles_Five(df.ER.IDQ, "Cavg1D")
df.ER.IDQ$CavgOED_IDQ  <- quantiles_Five(df.ER.IDQ, "CavgOED")
df.ER.IDQ$Cavg1WOED_IDQ  <- quantiles_Five(df.ER.IDQ, "Cavg1WOED")
df.ER.IDQ$Cavg2WOED_IDQ  <- quantiles_Five(df.ER.IDQ, "Cavg2WOED")
df.ER.IDQ$CavgTE_IDQ  <- quantiles_Five(df.ER.IDQ, "CavgTE")

plot_Ctrough1D <- create_covariate_plot("Ctrough1D")
plot_Cavg1D <- create_covariate_plot("Cavg1D")
plot_Cavg1WOED <- create_covariate_plot("Cavg1WOED")
plot_CtroughOED <- create_covariate_plot("CtroughOED")
plot_CavgOED <- create_covariate_plot("CavgOED")
plot_CavgTE <- create_covariate_plot("CavgTE")

model_comparison <- grid.arrange(plot_Ctrough1D, plot_Cavg1D, plot_Cavg1WOED, plot_CtroughOED,plot_CavgOED,plot_CavgTE,ncol = 3)
ggsave("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100/model comparision results_linear_5.tiff",
      plot = model_comparison, 
     width = 15, height = 8, dpi = 400, units = "in")

plot_Ctrough1D_L <- create_covariate_plot("Ctrough1D")+ scale_x_log10(labels = custom_log_labels) + coord_cartesian(ylim = c(0, 1), xlim = c(100, NA))
plot_Cavg1D_L <- create_covariate_plot("Cavg1D")+ scale_x_log10(labels = custom_log_labels) + coord_cartesian(ylim = c(0, 1), xlim = c(100, NA))
plot_Cavg1WOED_L <- create_covariate_plot("Cavg1WOED")+ scale_x_log10(labels = custom_log_labels) + coord_cartesian(ylim = c(0, 1), xlim = c(100, NA))
plot_CtroughOED_L <- create_covariate_plot("CtroughOED")+ scale_x_log10(labels = custom_log_labels) + coord_cartesian(ylim = c(0, 1), xlim = c(100, NA))
plot_CavgOED_L <- create_covariate_plot("CavgOED")+ scale_x_log10(labels = custom_log_labels) + coord_cartesian(ylim = c(0, 1), xlim = c(100, NA))
plot_CavgTE_L <- create_covariate_plot("CavgTE")+ scale_x_log10(labels = custom_log_labels) + coord_cartesian(ylim = c(0, 1), xlim = c(100, NA))
model_comparison_L <- grid.arrange(plot_Ctrough1D_L, plot_Cavg1D_L, plot_Cavg1WOED_L, plot_CtroughOED_L,plot_CavgOED_L,plot_CavgTE_L,ncol = 3)
ggsave("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100/model comparision results_log_5.tiff",
      plot = model_comparison_L, 
     width = 15, height = 8, dpi = 400, units = "in")

```
##5.4 Obtain slope, AIC, and P value
```{r}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
df.ER.IDQ <- read.csv("df_ER_IDQ.csv")

# abstract the slope, AIC and wald test
covariates <- c( "Ctrough1D", "Cavg1D","CtroughOED", "CavgOED", "Cavg1WOED","CavgTE")
logistic_formulas <- sapply(covariates, function(x) as.formula(paste('EVENT ~', x)))
logistic_Results <- lapply(logistic_formulas, function(x) glm(x, family = binomial(logit), data = df.ER.IDQ))
logistic_result  <- logistic_analysis(logistic_Results,covariates)%>% 
                    rownames_to_column(var = "Variable")


logistic_formulas_log <- sapply(covariates, function(x) as.formula(paste('EVENT ~ log(', x, ')')))
logistic_Results_log <- lapply(logistic_formulas_log, function(x) glm(x, family = binomial(logit), data = df.ER.IDQ))
logistic_result_log  <- logistic_analysis(logistic_Results_log,covariates)%>% 
                    rownames_to_column(var = "Variable")


wb_model <- createWorkbook()
addWorksheet(wb_model, "log transform")
addWorksheet(wb_model, "no log transform")

writeData(wb_model, sheet = "log transform", x = logistic_result_log)
writeData(wb_model, sheet = "no log transform", x = logistic_result)

setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO1_HL24_ii24_500&100")
saveWorkbook(wb_model, file = "model comparison.xlsx", overwrite = TRUE)

```

#6.1000 replications
##6.1 loop
- generate 1000 unique TTE datasets (the same calculation method as for a single simulation);
- generate 1000 df.exp dataset.
- EO1: shape = 0.65, scale = 100;
- EO2: shape = 2, scale = 240;
```{r}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis")
##input the PKPD individual parameters
parameter <- read.csv("estimated individual PK parameters.csv")
# mrgsolve model
PKPD_model<- mread_cache("PKPD_tumor_DH2_AE_LDR.mod") 

## Dose level for the 1 to 500 ID
FHDOSE <- 200
FMDOSE <- 100
FLDOSE <- 60

## Dose level for the 501 to 1000 ID
HDOSE <- 500
MDOSE <- 200
LDOSE <- 100

event.shape <-2
event.scale <- 240

set.seed(2025)
seeds <- sample(10:10000, 1000)

logistic_results_list <- list()
logistic_results_log_list <- list()
CoxPH_list <- list()

for (seed in seeds) {
     
      # Bootstrap PK parameters for 1000 IDs
        id.seed = seed
        set.seed(id.seed)
        
        ID.unique <- unique(parameter$SUBJID) 
        ID.bootstrap <- sample(ID.unique, 1000, replace = TRUE)


        iparameter <- data.frame()
       
       for (i in 1:length(ID.bootstrap)) {
                id <- ID.bootstrap[i]
                rows_for_id <- parameter[parameter$SUBJID == id, ]
                rows_for_id$NEWID <- i
                iparameter<- bind_rows(iparameter, rows_for_id)
         }
        
        iparameter <- iparameter %>% rename(ID=NEWID)

        iparameter.allID <- iparameter%>%
                    mutate(
                          DOSEI = ifelse(ID < 501, FHDOSE, HDOSE),
                          DOSEII = ifelse(ID < 501, FMDOSE, MDOSE),
                          DOSEIII = ifelse(ID < 501, FLDOSE, LDOSE),
                          KA = KA * 20,
                          CL = CL * 5
                        ) %>%
                    select(-SUBJID, -D2, -ALAG1)
       

        ID.MAX <-max(iparameter.allID$ID)
        evnt <- ev(amt=0, ii=24, ID=1:ID.MAX)
        
        set.seed(seed)
        out.pkpd <- PKPD_model%>%
                    idata_set( iparameter.allID)%>%
                    ev(evnt)%>%
                    mrgsim(
                       tgrid = c(seq(0, 24*600, by = 1)),
                       carry.out = "EVID", 
                       recsort = 3,
                       atol = 1e-12,
                       rtol = 1e-10 )

        out_df <- as.data.frame(out.pkpd)

        # calculate the exposure metrics
        exp <- out_df %>% 
          filter(EVID == 0) %>%
          select(-EVID,-GUT,-CENT,-PERIPH,-KA, -V2, -Q, -V3, -TR, -LPBase, -LPSlope,
                 -KG, -KD, -EMAX, -EC50, -Ktol)%>%
          mutate(DAY = ceiling(time/24),
                 CP = if_else(CP < 0, 0, CP), # replace the really small CP to 0
                 AUC = if_else(AUC < 0, 0,AUC))%>%  # replace the negative AUC to 0
          filter(time > 0)%>%
          mutate(CavgTE = AUC/time)%>%  # average concentration time to event
          group_by(ID, DAY) %>%
          mutate(Cmax = max(CP),
                 Ctrough = tail(CP,1)) %>%
          rename(DOSE=Dose) %>%
          ungroup() 
  
         #used to plot the first dosing interval profile
          exp.1.hour<- exp %>%
                    rename(TumorB= Tumor_0,
                           AUCTE=AUC)%>%
          select(ID,DAY,DOSE, AE,time,CL,TumorB, Tumor, CP,Cmax,Ctrough,AUCTE,CavgTE)

        # used to conduct ER analysis 
          exp.1<- exp.1.hour%>% filter(time %% 24 == 0)

        AUC1D <- exp.1 %>%
                  group_by(ID) %>%
          # Calculate the last AUCTE for each day for each ID
                  group_by(DAY, .add = TRUE) %>%
                  summarize(LastAUCTE = last(AUCTE), .groups = 'drop_last') %>%
  # Calculate daily AUC for each ID
                    group_by(ID) %>%
                    mutate(AUC1D = LastAUCTE - lag(LastAUCTE, default=0)) %>%
                    ungroup()%>%
                    select(-LastAUCTE)%>%
                    mutate(AUC1D = if_else(AUC1D < 0, 0,AUC1D))

                  Combined.data <- left_join(exp.1, AUC1D, by = c("ID", "DAY"))

# calculate all possible necessary exposure matrix
        exp.2 <- Combined.data%>%
          group_by(ID) %>%
          mutate(AUC1W = rollsum(AUC1D, 7, fill = NA, align = "right"),
                 AUC2W = rollsum(AUC1D, 14, fill = NA, align = "right"),
                 AUC3W = rollsum(AUC1D, 21, fill = NA, align = "right"),
                 AUC4W = rollsum(AUC1D, 28, fill = NA, align = "right"),
                 Cavg = AUC1D / 24,
                 Cavg1W = AUC1W / (24*7),
                 Cavg2W = AUC2W / (24*14),
                 Cavg3W = AUC3W / (24*21),
                 Cavg4W = AUC4W / (24*28)) %>%
          ungroup()%>%
          select(-time, -AUCTE,-AUC1D,-AUC1W,-AUC2W,-AUC3W,-AUC4W)%>%
          mutate(Cavg1W = ifelse(is.na(Cavg1W), CavgTE, Cavg1W),
                 Cavg2W = ifelse(is.na(Cavg2W), CavgTE, Cavg2W),
                 Cavg3W = ifelse(is.na(Cavg3W), CavgTE, Cavg3W),
                 Cavg4W = ifelse(is.na(Cavg4W), CavgTE, Cavg4W))

        exp.3 <- exp.2 %>%
                  group_by(ID) %>%
                  mutate(
                        Cavg1WC1 = if_else(DAY > 7, Cavg1W, Cavg1W[DAY == 7]),
                        Cavg2WC1 = if_else(DAY > 14, Cavg2W, Cavg2W[DAY == 14]),
                        Cavg4WC1 = if_else(DAY > 28, Cavg4W, Cavg4W[DAY == 28]),
                        CavgTE2WC1 = if_else(DAY > 14, CavgTE, Cavg2W[DAY == 14]),
                        CavgTE4WC1 = if_else(DAY > 28, CavgTE, Cavg4W[DAY == 28])
                 ) %>%
          ungroup()

## Calculate the accumulative average dose
          df.exp <- exp.3 %>%
                 group_by(ID) %>%
                 arrange(ID, DAY) %>%
                 mutate(CMDOSE = cumsum(DOSE)) %>%
                 ungroup() %>%
                 mutate(avgDOSE = CMDOSE/DAY) %>%
                 select(ID, DAY, DOSE,AE, CMDOSE, avgDOSE,  everything())      
                       
  # generate TTE dataset
       set.seed(seed)
       n.event = 750
       n.censor= 250
       Sample.event <- tibble(ID = 1:n.event) %>% 
                mutate(time = 1 + ceiling(rweibull(n.event, shape = event.shape, scale = event.scale )),
                       event=1) 

      set.seed(seed+6)
      censor.time <- sample(1:600, n.censor, replace = TRUE)

      Sample.censor <- tibble(ID = 1:n.censor) %>% 
                       mutate(time = censor.time,
                       event=0) 

      merge.data <- rbind(Sample.event, Sample.censor)

      TTE <- merge.data %>%
             mutate(event = if_else(time > 600, 0, event),
             ID = sample(1:1000, n(), replace = FALSE))%>% 
             arrange(ID)

      # merge the TTE dataset with df.ER dataset
      df.ER <- data.frame()

      for (i in 1:1000) {
        single <- TTE$time[i]
        rows_for_id <- df.exp[df.exp$ID == i, ]
        max_day <- max(rows_for_id$DAY, na.rm = TRUE)
  
        if (max_day < single) {
          rows_for_id$EVENT <- 0
          max_row <- which.max(rows_for_id$DAY)
          rows_for_id$LAST <- ifelse(1:nrow(rows_for_id) == max_row, 1, 0)
        } else {
    #Cut off the extra data that Day > single
          rows_for_id <- rows_for_id[rows_for_id$DAY <= single, ]
          max_row <- which.max(rows_for_id$DAY)
    #match the Event when TTE has censored values
          rows_for_id$EVENT <- ifelse(1:nrow(rows_for_id) == max_row, TTE$event[TTE$ID == i], 0)
          rows_for_id$LAST <- ifelse(1:nrow(rows_for_id) == max_row, 1, 0)
        }
         df.ER <- bind_rows(df.ER, rows_for_id)
      }

      analysis <- df.ER %>% filter(LAST == 1)

    First_day_conc <- df.exp %>% filter(DAY==1)%>% select(ID, Ctrough, Cavg)%>% rename(Ctrough1D=Ctrough, Cavg1D=Cavg)
    df.ER_correct <-  left_join(analysis, First_day_conc, by = c("ID"))

    df.ER.IDQ <-df.ER_correct %>%
                  rename(CmaxOED=Cmax,
                         CtroughOED=Ctrough,
                         CavgOED=Cavg,
                         Cavg1WOED=Cavg1W,
                         Cavg2WOED=Cavg2W,
                         Cavg4WOED=Cavg4W)
    
     covariates <- c( "Ctrough1D", "Cavg1D","CtroughOED", "CavgOED", "Cavg1WOED","CavgTE")
    # univariate Cox PH regression_continuous covariate
    univ_formulas <- sapply(covariates, function(x) as.formula(paste('Surv(DAY, EVENT) ~', x)))
    univ_models <- lapply(univ_formulas, function(x) { coxph(x, data = df.ER.IDQ) })
    univ_con_result <- univ_con(univ_models)

    # abstract the slope, AIC and wald test
   
    logistic_formulas <- sapply(covariates, function(x) as.formula(paste('EVENT ~', x)))
    logistic_Results <- lapply(logistic_formulas, function(x) glm(x, family = binomial(logit), data = df.ER.IDQ))
    logistic_result  <- logistic_analysis(logistic_Results,covariates)%>% 
                        rownames_to_column(var = "Variable")

    logistic_formulas_log <- sapply(covariates, function(x) as.formula(paste('EVENT ~ log(', x, ')')))
    logistic_Results_log <- lapply(logistic_formulas_log, function(x) glm(x, family = binomial(logit), data = df.ER.IDQ))
    logistic_result_log  <- logistic_analysis(logistic_Results_log,covariates)%>% 
                        rownames_to_column(var = "Variable")

    logistic_results_list[[as.character(seed)]] <- logistic_result
    logistic_results_log_list[[as.character(seed)]] <- logistic_result_log
    CoxPH_list[[as.character(seed)]] <- univ_con_result

}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO2_HL24_ii24_500&200") 
saveRDS(logistic_results_list, "EO2_logistic_results_500&200.rds")
saveRDS(logistic_results_log_list, "EO2_logistic_results_log_500&200.rds")
saveRDS( CoxPH_list, "EO2_CoxPH_500&200.rds")

```

##6.2 Result clearning and save
### common functions
```{r}
Result_clean <- function(logistic_test) {
  combined_results <- list()
  # Loop through each element in the logistic_test list
  for (Seed in names(logistic_test)) {
    df <- logistic_test[[Seed]]
    df$Seed <- Seed
    combined_results[[Seed]] <- df
  }
  
  # Combine all the data.frames in the combined_results list into a single data.frame
  combined_df <- do.call(rbind, combined_results)
  combined_df <- combined_df[, c("Seed", "Variable", "Slope", "AIC", "P.Value")]
  combined_df$Group <- ifelse(combined_df$P.Value >= 0.05, "p>=0.05", "p<0.05")
  combined_df$Odd.ratio <- exp(combined_df$Slope)

  return(combined_df)
}

# Abstract p values and summarize the statistical significance percentage
summarize_pvalue_percentage <- function(data) {
  con_var <- c("Ctrough1D","Cavg1D", "CtroughOED", "CavgOED", "Cavg1WOED", "CavgTE")
  filtered_data <- data[data$Variable %in% con_var, ]
  summary_df <- filtered_data %>%
    group_by(Variable) %>%
    summarise(
      Total = n(),
      Count_LT_0.05 = sum(P.Value < 0.05),
      Percentage_LT_0.05 = (Count_LT_0.05 / Total) * 100
    )
  
  # Return the summarized data frame
  return(summary_df)
}


Median_95CI <- function(data) {
  data %>%
    group_by(Variable) %>%
    summarise(
      Mean = mean(Odd.ratio, na.rm = TRUE),
      StdDev = sd(Odd.ratio, na.rm = TRUE),
      n = sum(!is.na(Odd.ratio)),
      Lower_95CI = ifelse(n > 1, Mean - 1.96 * (StdDev / sqrt(n)), NA),
      Upper_95CI = ifelse(n > 1, Mean + 1.96 * (StdDev / sqrt(n)), NA),
      Odd.ratio = median(Odd.ratio, na.rm = TRUE),
      .groups = "drop"
    ) 
}

Result_clean_cox <- function(test) {
  combined_results <- list()
 for (Seed in names(test)) {
    df <- test[[Seed]]

    df_processed <- as.data.frame(df, stringsAsFactors = FALSE)
    
    df_processed$Variable <- rownames(df)
    rownames(df_processed) <- NULL

    # Reorder columns to place 'Variable' first, if it exists
    if ("Variable" %in% names(df_processed)) {
      df_processed <- df_processed[, c("Variable", setdiff(names(df_processed), "Variable"))]
    }
    
    # Convert relevant columns from character to numeric, if necessary
    # Note: "HR (95% CI for HR)" is a string and may need special handling
    numeric_cols <- c("beta", "wald.test", "P.Value")
    for (col in numeric_cols) {
      if (col %in% names(df_processed)) {
        df_processed[[col]] <- as.numeric(df_processed[[col]])
        if (any(is.na(df_processed[[col]]))) {
          warning(paste("Conversion to numeric failed for column", col, "in Seed", Seed))
        }
      }
    }
    
    df_processed$Seed <- Seed
    combined_results[[Seed]] <- df_processed
  }
  
  # Combine all data frames into a single data frame
  CoxPH_results_df <- do.call(rbind, combined_results)
  
  # Reset row names
  rownames(CoxPH_results_df) <- NULL
  
  return(CoxPH_results_df)
}


Median_95CI_cox <- function(data) {
  data %>%
    group_by(Variable) %>%
    summarise(
      Mean = mean(Hazard.ratio, na.rm = TRUE),
      StdDev = sd(Hazard.ratio, na.rm = TRUE),
      n = sum(!is.na(Hazard.ratio)),
      Lower_95CI = ifelse(n > 1, Mean - 1.96 * (StdDev / sqrt(n)), NA),
      Upper_95CI = ifelse(n > 1, Mean + 1.96 * (StdDev / sqrt(n)), NA),
      Hazard.ratio = median(Hazard.ratio, na.rm = TRUE),
      .groups = "drop"
    ) 
}

```

### clear and save
```{r}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER1_DH2_EO2_HL24_ii24_500&200") 
logistic_results_list <- readRDS("EO2_logistic_results_500&200.rds")
logistic_results_log_list <- readRDS("EO2_logistic_results_log_500&200.rds")
CoxPH_list <- readRDS("EO2_CoxPH_500&200.rds")
# clear the results
logistic_results_df <- Result_clean(logistic_results_list)
logistic_results_log_df <- Result_clean(logistic_results_log_list)
CoxPH_results_df <- Result_clean_cox(CoxPH_list)
CoxPH_results_df <-CoxPH_results_df %>% mutate(Hazard.ratio = exp(beta))

# summary the p_value
p_values_logistic_results <- summarize_pvalue_percentage(logistic_results_df)
p_values_logistic_results_log <- summarize_pvalue_percentage(logistic_results_log_df)
p_values_CoxPH_results <- summarize_pvalue_percentage(CoxPH_results_df)
# summary the odd ratios
Odd_logistic_results<- Median_95CI(logistic_results_df)
Odd_logistic_results_log<- Median_95CI(logistic_results_log_df)
Hazard_CoxPH_results<- Median_95CI_cox(CoxPH_results_df)

# combine the results and save
loop_logistic_summary <- left_join(p_values_logistic_results, Odd_logistic_results, by = "Variable")
loop_logistic_log_summary <- left_join(p_values_logistic_results_log, Odd_logistic_results_log, by = "Variable")
loop_CoxPH_summary <- left_join(p_values_CoxPH_results, Hazard_CoxPH_results, by = "Variable")

loop_logistic_summary <-loop_logistic_summary%>%
                        select(Variable,n, Percentage_LT_0.05, Odd.ratio, Lower_95CI, Upper_95CI)%>%
                        rename(`%(p<0.05)` = Percentage_LT_0.05)
loop_logistic_log_summary <-loop_logistic_log_summary%>%
                        select(Variable,n, Percentage_LT_0.05, Odd.ratio, Lower_95CI, Upper_95CI)%>%
                        rename(`%(p<0.05)` = Percentage_LT_0.05)

loop_CoxPH_summary <-loop_CoxPH_summary %>%
                        select(Variable,n, Percentage_LT_0.05, Hazard.ratio, Lower_95CI, Upper_95CI)%>%
                        rename(`%(p<0.05)` = Percentage_LT_0.05)


# Create a new workbook
wb_summary <- createWorkbook()

# Add sheets for no-log and log-transformation results
addWorksheet(wb_summary, "logit_nolog")
addWorksheet(wb_summary, "logit_log")
addWorksheet(wb_summary, "CoxPH")
# Write the summaries into the respective sheets
writeData(wb_summary, sheet = "logit_nolog", x = loop_logistic_summary )
writeData(wb_summary, sheet = "logit_log", x = loop_logistic_log_summary)
writeData(wb_summary, sheet = "CoxPH", x = loop_CoxPH_summary)

setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH2_2Dose_ORR_TTE/ER2_DH2_EO2_HL24_ii24_500&200")  
saveWorkbook(wb_summary, file = "EO2_summary_500&200.xlsx", overwrite = TRUE)

saveRDS(logistic_results_df, "EO2_df_logit_results_500&200.rds")
saveRDS(logistic_results_log_df, "EO2_df_logit_results_log_500&200.rds")
saveRDS(CoxPH_results_df, "EO2_df_CoxPH_results_500&200.rds")
```



