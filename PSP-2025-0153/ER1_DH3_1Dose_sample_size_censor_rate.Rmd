---
title: "ER1_empirical dose with 1 DOSE levels(DH3)"
author: "Xuefen Yin"
date: "2024-12-24"
output: html_document
---

# R setup
```{r setup, echo = F}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

rm(list=ls(all=TRUE))

library(tidyverse)
library(mrgsolve)
library(ggplot2)
library(survival)
library(survminer)
library(gridExtra)
library(muhaz)
library(zoo)
library(openxlsx)
new_path <- paste("C:/rtools40/usr/bin", "C:/rtools40/mingw64/bin", Sys.getenv("PATH"), sep=";")
Sys.setenv(PATH = new_path)

```

# Simulation code

The simulation procedure follows the following steps:

1.  **common functions**

-   Create a loop function. For each iteration of the loop:

    a.  Bootstrap individual PK parameters based on the specified sample size with replacement, and adjust them to let the final PK profile reaches steady-state at day 5.
    b.  Run the PK simulation to generate PK profiles and calculate relevant exposure metrics;
    c.  Generate TTE data based on the defined event onset settings and censoring percentage;
    d.  Create the df.ER dataset by integrating the TTE dataset to exposure metrics dataset, aligning on time points.This process involves handling each ID individually and combining them sequentially. For each ID:1) Extract all records for the selected ID; 2)Determine the last day in the dosing record for this ID and compare it with its corresponding time point in the TTE dataset (for instance, ID=10 is matched with the TTE dataset's 10th time point); 3) If the last dosing day is greater than or equal to the TTE time point, remove any data beyond this time and align the EVENT from TTE with the new final day of the dosing record; If the last dosing day is less than the TTE time point, the EVENT is censored;
    e.  Create df.ER.IDQ dataset, including both time dependent and time independent exposure metrics;
    f.  Perform exposure response analysis;
    g.  Abstract and save necessary results.
    
2.  **Input the initial parameter dataset and load the model**
-   Load the individual PK parameter dataset;
-   Load the emperical dosing history;
-   Load a two-compartment PK model;

3.  **Define Simulation Parameters and run simulation**

-   Specify the sample size, Weibull function parameters, and the percentage of censoring;Generate 500 random seeds for reproducibility and iterate through them in a loop.

-   Run Simulations and Save Results: For each combination of conditions (sample size, censoring percentage, and event onset setting), perform the simulation and save the results.

#1 Common functions

```{r}
loop <- function(DI, Case.fix, seed, parameter.451, dose.451, event.shape, event.scale, Sample_size, Censor.percentage){
       # seed=112
      # random solected doing records based on ID
       set.seed(seed-10)
       ID.dose <- unique(dose.451$SUBJID) 
       dose.bootstrap <- sample(ID.dose, Sample_size, replace = TRUE)

       dose.allID <- data.frame()

       for (i in 1:length(dose.bootstrap)) {
         id <- dose.bootstrap[i]
         rows_for_id <- dose.451[dose.451$SUBJID == id, ]
         rows_for_id$NEWID <- i
         dose.allID <- bind_rows(dose.allID, rows_for_id)
       }

       dose.allID  <- dose.allID %>% rename(ID=NEWID) %>% select(-SUBJID)

       # random bootstrap the SUBJID with a fixed seed
       seed1 <- seed+6
       set.seed(seed1)
       ID.unique <- unique(parameter.451$SUBJID) 
       ID.bootstrap <- sample(ID.unique, Sample_size, replace = TRUE)

       iparameter <- data.frame()

       for (i in 1:length(ID.bootstrap)) {
         id <- ID.bootstrap[i]
         rows_for_id <- parameter.451[parameter.451$SUBJID == id, ]
         rows_for_id$NEWID <- i
         iparameter<- bind_rows(iparameter, rows_for_id)
       }

       iparameter <- iparameter %>% rename(ID=NEWID)
       
       # adjust the parameters to reflect the corresponding PK profiles
       if (Case.fix == 1) {
           iparameter.allID <- iparameter%>%
                            mutate(KA=KA*20,
                            CL=CL*18)  

       } else if (Case.fix == 2) {
           iparameter.allID <- iparameter%>%
                            mutate(KA=KA*20,
                            CL=CL*5)   
       } else if (Case.fix == 3) {
           iparameter.allID <- iparameter%>%
                     mutate(KA=KA*3,
                     CL=CL/120, 
                     V2=V2/40,
                     V3=V3/30,
                     Q=Q/50)  
       }

       # run the simulation to get PK profiles
       idata.allID <- left_join(dose.allID, iparameter.allID, by = "ID")
       idata.allID = idata.allID[!is.na(idata.allID$DOSE), ]
       # some IDs do not have estimated parameters
       idata.allID = idata.allID[!is.na(idata.allID$KA), ]
       
       out <- mrgsim_df(mod, 
                        idata.allID,
                        recover = c("CL","SUBJID"), 
                        carry.out = "EVID", 
                        recsort = 3,
                        tgrid = seq(0, 14400, by = 1))

       exp <- out %>% 
         as_tibble() %>% 
         distinct() %>%
         group_by(time) %>%
         filter(EVID != 1) %>%
         ungroup()%>%
         mutate(DAY = ceiling(time/24),
                CP = if_else(CP < 0, 0, CP), # replace the negative CP to 0
                AUC = if_else(AUC < 0, 0,AUC))%>%  # replace the negative AUC to 0
         filter(time > 0)%>%
         mutate(Cavg = AUC/time)%>%  # average concentration time to event
         group_by(ID, DAY) %>%
         mutate(Cmax = max(CP),
                Ctrough = tail(CP,1)) %>%
         ungroup()

       # adding DOSE and SEQ columns
       Dose.IDindex <- dose.allID %>%
           select(ID, DAY, DOSE, SEQ) %>%
           mutate(DOSE = if_else(is.na(DOSE), 0, DOSE))

       exp.0 <-  left_join(exp,Dose.IDindex, by = c("ID", "DAY"))
       
       # clear the dataset 
       #used to plot the first dosing interval profile
       exp.1 <- exp.0 %>%
                 filter(time %% 24 == 0)%>%
                 select(-EVID,-GUT,-CENT,-PERIPH)%>%
                 rename(AUCTE=AUC,
                        CavgTE= Cavg)%>%
                 select(ID,SUBJID,DAY,time,DOSE,SEQ,CL,CP,Cmax,Ctrough,AUCTE,CavgTE)%>%
                 mutate(DOSE = if_else(is.na(DOSE), 0, DOSE))

       # get the daily AUC
       AUC1D <- exp.1 %>%
         arrange(ID, DAY) %>%
         group_by(ID) %>%
         group_by(DAY, .add = TRUE) %>%
         summarize(LastAUCTE = last(AUCTE), .groups = 'drop_last') %>%
         group_by(ID) %>%
         mutate(AUC1D = LastAUCTE - lag(LastAUCTE, default=0)) %>%
         ungroup()%>%
         select(-LastAUCTE)%>%
         mutate(AUC1D = if_else(AUC1D < 0, 0,AUC1D))

       Combined.data <- left_join(exp.1, AUC1D, by = c("ID", "DAY"))

       # calculate all possible necessary exposure matrix
       df.exp <- Combined.data%>%
                group_by(ID) %>%
                mutate(AUC1W = rollsum(AUC1D, 7, fill = NA, align = "right"),
                AUC2W = rollsum(AUC1D, 14, fill = NA, align = "right"),
                AUC3W = rollsum(AUC1D, 21, fill = NA, align = "right"),
                AUC4W = rollsum(AUC1D, 28, fill = NA, align = "right"),
                Cavg = AUC1D / 24,
                Cavg1W = AUC1W / (24*7),
                Cavg2W = AUC2W / (24*14),
                Cavg3W = AUC3W / (24*21),
                Cavg4W = AUC4W / (24*28)) %>%
         ungroup()%>%
         mutate(AUC1W = ifelse(is.na(AUC1W), AUCTE, AUC1W),
                AUC2W = ifelse(is.na(AUC2W), AUCTE, AUC2W),
                AUC3W = ifelse(is.na(AUC3W), AUCTE, AUC3W),
                AUC4W = ifelse(is.na(AUC4W), AUCTE, AUC4W),
                Cavg1W = ifelse(is.na(Cavg1W), CavgTE, Cavg1W),
                Cavg2W = ifelse(is.na(Cavg2W), CavgTE, Cavg2W),
                Cavg3W = ifelse(is.na(Cavg3W), CavgTE, Cavg3W),
                Cavg4W = ifelse(is.na(Cavg4W), CavgTE, Cavg4W))%>%
         select(-time, -AUCTE,-AUC1D,-AUC1W,-AUC2W,-AUC3W,-AUC4W,-Cavg3W)%>%
                 group_by(ID) %>%
                 mutate(Cavg1WC1 = if_else(DAY > 7, Cavg1W, Cavg1W[DAY == 7]),
                        Cavg2WC1 = if_else(DAY > 14, Cavg2W, Cavg2W[DAY == 14]),
                        Cavg4WC1 = if_else(DAY > 28, Cavg4W, Cavg4W[DAY == 28])) %>%
                 ungroup()


      # Generate TTE dataset
       set.seed(seed)
       #Calculate the number of events and censored observations based on the censoring percentage
       n.censor= ceiling(Censor.percentage * Sample_size)
       n.event = Sample_size - n.censor
       # using weibull function to generate event time points(day)
       Sample.event <- tibble(ID = 1:n.event) %>% 
                       mutate(time = 1 + ceiling(rweibull(n.event, shape = event.shape, scale = event.scale )),
                              event=1) 

       set.seed(seed+6)
       # censored observations are randomly selected from the follow up period
       censor.time <- sample(1:600, n.censor, replace = TRUE)
       Sample.censor <- tibble(ID = 1:n.censor) %>% 
                        mutate(time = censor.time,event=0) 

       merge.data <- rbind(Sample.event, Sample.censor)

       TTE <- merge.data %>%
              mutate(event = if_else(time > 600, 0, event),
              ID=sample(1:Sample_size, n(), replace=FALSE))%>%
              arrange(ID)

      # merge the TTE dataset with df.ER dataset
       df.ER <- data.frame()

      for (i in 1:Sample_size) {
        single <- TTE$time[i]
        rows_for_id <- df.exp[df.exp$ID == i, ]
        max_day <- max(rows_for_id$DAY, na.rm = TRUE)
  
        if (max_day < single) {
          rows_for_id$EVENT <- 0
          max_row <- which.max(rows_for_id$DAY)
          rows_for_id$LAST <- ifelse(1:nrow(rows_for_id) == max_row, 1, 0)
        } else {
    #Cut off the extra data that Day > single
          rows_for_id <- rows_for_id[rows_for_id$DAY <= single, ]
          max_row <- which.max(rows_for_id$DAY)
    #match the Event when TTE has censored values
          rows_for_id$EVENT <- ifelse(1:nrow(rows_for_id) == max_row, TTE$event[TTE$ID == i], 0)
          rows_for_id$LAST <- ifelse(1:nrow(rows_for_id) == max_row, 1, 0)
        }
         df.ER <- bind_rows(df.ER, rows_for_id)
      }


      analysis <- df.ER %>% filter(LAST == 1)

        # ================only Using first day data points =====================
        ## Group the IDs based on the quantiled exposure at the first day(df.ER.IDQ)
           ## Group the IDs based on the quantiled exposure at the first day(df.ER.IDQ)
            df.ER.ID <- df.ER %>%
            filter(SEQ == 1) %>%
            filter(DAY == 1) %>%
            select(SUBJID, ID, DOSE, CL, Ctrough, Cavg,Cavg2WC1,Cavg4WC1 )%>%
            rename(Ctrough1D=Ctrough,
                   Cavg1D=Cavg)
          # last day CavgTE and EVENT & DAY
           G.ID <-  analysis[,c("ID","DAY","Ctrough", "Cavg","Cavg1W","Cavg2W","Cavg4W","CavgTE", "EVENT","LAST")]%>%
                    rename(CtroughOED=Ctrough,
                           CavgOED=Cavg,
                           Cavg1WOED=Cavg1W,
                           Cavg2WOED=Cavg2W,
                           Cavg4WOED=Cavg4W)

           df.ER.IDQ <- merge(df.ER.ID, G.ID, by = "ID")%>%
                        select(ID, SUBJID, DAY, DOSE, CL, LAST,EVENT, 
                               Ctrough1D, Cavg1D, CavgOED,Cavg1WOED,Cavg2WOED,Cavg4WOED,CavgTE)
           
           #1. conduct linear logistic regression
            covariates <- colnames(df.ER.IDQ)[c(5,8:14)]
            
            logistic_formulas <- sapply(covariates, function(x) as.formula(paste('EVENT ~', x)))
            logistic_Results <- lapply(logistic_formulas, function(x) glm(x, family = binomial(logit), data = df.ER.IDQ))
            logistic_result <- logistic_analysis(logistic_Results,covariates)%>%
                          rownames_to_column(var = "Variable")
           
            
             univ_formulas <- sapply(covariates, function(x) as.formula(paste('Surv(DAY, EVENT) ~', x)))
             univ_models <- lapply(univ_formulas, function(x) { coxph(x, data = df.ER.IDQ) })
             univ_con_result <- univ_con(univ_models)

            return(list(logistic_result = logistic_result, univ_cox_result = univ_con_result))
} 

#1.extract results from univariate Cox PH models_continuous
logistic_analysis <- function(logistic_Results, covariates) {
  logistic_summaries <- lapply(logistic_Results, summary)
  
  logistic.results <- lapply(seq_along(logistic_summaries), function(i) {
    x <- logistic_summaries[[i]]
    P.value <- signif(x$coefficients[2, 4], digits=3)
    Slope <- signif(x$coefficients[2, 1], digits=3)
    AIC <- round(AIC(logistic_Results[[i]]), 1)   # Use the actual model object, not the summary
    res <- c(Slope, AIC, P.value)
    names(res) <- c("Slope","AIC", "P.Value")
    return(res)
  })
  
  # Convert the list of results to a dataframe
  result_df <- as.data.frame(do.call(rbind, logistic.results))
  row.names(result_df) <- covariates  # Add row names
  
  return(result_df)
}

#3.extract results from univariate Cox PH models_continuous
univ_con <- function(univ_models) {
    univ_results <- lapply(univ_models, function(x) {
    x <- summary(x)  # Summarize the model
    # Extract and format the results
    P.value <- signif(x$wald["pvalue"], digits=3)
    wald.test <- signif(x$wald["test"], digits=3)
    beta <- signif(x$coef[1], digits=3)  # Coefficient beta
    HR <- signif(exp(x$coef[1]), digits=3)  # Hazard Ratio (HR)
    HR.confint.lower <- signif(x$conf.int[,"lower .95"], 3)
    HR.confint.upper <- signif(x$conf.int[,"upper .95"], 3)
    HR <- paste0(HR, " (",
                 HR.confint.lower, "-", HR.confint.upper, ")")
    res <- c(beta, HR, wald.test, P.value)
    names(res) <- c("beta", "HR (95% CI for HR)", "wald.test", "P.Value")
    return(res)
  })
  # Convert the list of results to a dataframe
  result_df <- t(as.data.frame(univ_results))
  return(result_df)
}
```


#2 input the initial dose and parameter dataset
```{r}
setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis")
# mrgsolve model
mod<- mread_cache("KP_2com.mod") 
# Clear the input dose dataset
parameter.451 <- read.csv("estimated individual PK parameters.csv")

dose<- read.csv("dosing record for study 309.csv")
dose.451 <- dose %>%
        mutate(DOSE = as.numeric(DOSE))%>%
        select(-X9)%>%
        mutate(FORM = case_when(
               FORM == "TABLET" ~ 3, 
               FORM == "CAPSULE" ~ 2),
               DOSE = if_else(DOSE == 0, NA, DOSE))%>%
        mutate(DAY = as.numeric(DAY), 
               time = (DAY - 1) * 24,
               C = "") %>%
       dplyr::select(C, SUBJID,time, DAY, DOSE, FORM, SEQ) %>%   
       mutate( evid =1,
               amt=DOSE,
               cmt=1)%>% 
       mutate( SUBJID = as.numeric(SUBJID))
```
#3. Define Simulation Parameters and run simulation 

Two TTE scenarios will be explored:

-   EO1: event.shape = 0.65, event.scale = 100;

-   EO2: event.shape = 2, event.scale = 240;

The sample size will be explored: 20, 50, 100, 250, 500, and 1000;

Two censored percentage will be explored: Censor.percentage= 25% or 80%.

The drug with PK2 profile was explored, but the code are able to used to evaluate other PK profiles.

```{r}
Sample_size = 20

# dose interval could be changed 
DI = 1 # DAY
Case.fix <- 2

event.shape <-0.65
event.scale <- 100

Censor.percentage <- 0.25

# Set a fixed seed for reproducibility
set.seed(2025)
# Randomly select 100 seeds from 1 to 100,000
seeds <- sample(10:10000, 500)

logistic_result <- list()
univ_cox_result <- list()

for (seed in seeds) {
    simulation_result <- loop(DI, Case.fix, seed, parameter.451, dose.451, event.shape, event.scale,Sample_size,Censor.percentage) 
    logistic_result[[as.character(seed)]] <- simulation_result$logistic_result
    univ_cox_result[[as.character(seed)]] <- simulation_result$univ_cox_result
  }

setwd("C:/Users/Xuefen.Yin/OneDrive - FDA/ER1 analysis/ER1_DH3_1Dose_size_censor")
saveRDS(logistic_result, "20ID_EO1_censor0.25_HL24_logit.rds")
saveRDS(univ_cox_result, "20ID_EO1_censor0.25_HL24_cox.rds")
```

#4 Backup_used to validate the code
- set a seed
- run the code within the loop function first without initiate the loop function
- check the function using the blow code
```{r}
# Dosing history and cummulative event rate
dose_label= c("0mg", "20mg", "40mg","60mg")
 EventDATA <- analysis %>%
                  select(DAY, EVENT)%>%
                  arrange(DAY)
     Utime <- unique(EventDATA$DAY)
     # Number at risk and number of events at each time
     ni <- sapply(Utime, function(t) sum(EventDATA$DAY >= t))
     di <- sapply(Utime, function(t) sum(EventDATA$DAY == t & EventDATA$EVENT == 1))
     Event_probs <- 1-cumprod(1-di/ni)

     CumEvent <- data.frame(DAY = Utime, PEvent = Event_probs* 100)
      
# Count and prepare totals
DosehistG <- df.ER %>%
  select(ID, DOSE,DAY) %>%
  count(DAY, DOSE, name = "freq") %>%
  group_by(DAY) %>%
  mutate(TOTAL = sum(freq)) %>%
  ungroup()%>%
  mutate(percentage = (freq / TOTAL) * 100)%>%
  mutate(DOSE = as.factor(DOSE))

custom_theme <- theme_classic() +
  theme(
    panel.grid.major = element_line(color = "gray70", linewidth = 0.5),  # Major grid lines
    panel.grid.minor = element_line(color = "gray90", linewidth = 0.25)  # Minor grid lines
  )
DE.plot <- ggplot() +
   geom_col(data = CumEvent, aes(x = DAY, y = PEvent), color = "grey40", fill = "grey40", alpha = 0.01) + 
   geom_line(data = DosehistG, aes(x = DAY, y = percentage, group = DOSE, color = DOSE), size = 1) +
   scale_x_continuous(name = "Days since first dose") +
   scale_y_continuous(name = "% of event", sec.axis = sec_axis(~ . * 1, name = "% of dose level")) +
   ggtitle("Dose vs event summary plot") +
   scale_color_discrete(name = "Dose", labels = dose_label) +
   custom_theme +
   theme(legend.title = element_blank(),
         legend.text = element_text(size = 12),
         plot.title = element_text(size = 14, hjust = 0.5, vjust = 0.5),
         axis.text.x = element_text(size = 10),
         axis.text.y = element_text(size = 10),
         axis.title.x = element_text(hjust = 0.5, size = 12),
         axis.title.y = element_text(hjust = 0.5, size = 12))

#typical CP plot for DH3
Typical_plot_A1 <- function(data, y_var, title) {
  ggplot(data, aes(x = DAY, y = !!sym(y_var), color = as.factor(ID))) +
    geom_point() +
    geom_line() +
    theme_classic() +
    theme(
      panel.background = element_rect(fill = "white"),
      panel.grid.major.y = element_line(color = "grey"),
      panel.grid.minor.x = element_line(color = "grey", linetype = 2),
      panel.grid.major.x = element_line(color = "grey"),
      legend.background = element_rect(fill = "transparent"),
      plot.title = element_text(hjust = 0.5)
    ) +
    scale_color_brewer(palette = "Paired") +
    labs(x = "Time (days)",
         y = y_var,
         title = title,
         color = "ID")
}
# Generate the typical exposure metrics plot
 ids <- df.exp %>%
      pull(ID) %>%
      unique()

  set.seed <- 999
  selected_ids <- sample(ids, 10)

    exp.10 <- df.exp %>% 
             filter(ID %in% selected_ids)

             CP.plot <- Typical_plot_A1(exp.10, "CP", "Typical CP Profile")
             Cavg.plot <- Typical_plot_A1(exp.10, "Cavg", "Typical Cavg Profile")
             Cavg1W.plot <- Typical_plot_A1(exp.10, "Cavg1W", "Typical Cavg1W Profile")
             Cavg2W.plot <- Typical_plot_A1(exp.10, "Cavg2W", "Typical Cavg2W Profile")
             Cavg4W.plot <- Typical_plot_A1(exp.10, "Cavg4W", "Typical Cavg4W Profile")
             CavgTE.plot <- Typical_plot_A1(exp.10, "CavgTE", "Typical CavgTE Profile")

     COMBINE_TP <- grid.arrange(CP.plot, Cavg.plot, Cavg1W.plot,  Cavg2W.plot, Cavg4W.plot, CavgTE.plot, ncol = 3)
```